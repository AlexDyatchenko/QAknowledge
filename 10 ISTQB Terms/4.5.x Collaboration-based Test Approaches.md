# Collaboration-based Test Approaches

Each of the above-mentioned test techniques has a particular objective with
respect to **defect detection**. 

Collaboration-based approaches, on the other hand, **focus *also* on defect avoidance** by collaboration and communication.

## Collaborative User Story Writing

A user story represents a feature that will be valuable to either a user or purchaser of a system or software. User stories have three critical aspects, called together the “3 C’s”:
- Card – the medium describing a user story (e.g., an index card, an entry in an electronic board)
- Conversation – explains how the software will be used (can be documented or verbal)
- Confirmation – [the acceptance criteria](#Acceptance-Criteria)

The most common format for a user story is “As a [role], I want [goal to be accomplished], so that I can
[resulting business value for the role]”, followed by the acceptance criteria.
Collaborative authorship of the user story can use techniques such as brainstorming and mind mapping.
The collaboration allows the team to obtain a shared vision of what should be delivered, by taking into
account three perspectives: business, development and testing.
Good user stories should be: Independent, Negotiable, Valuable, Estimable, Small and Testable
(INVEST). If a stakeholder does not know how to test a user story, this may indicate that the user story is
not clear enough, or that it does not reflect something valuable to them, or that the stakeholder just needs
help in testing (Wake 2003).

## Acceptance Criteria

Acceptance criteria for a user story are the conditions that an implementation of the user story must meet
to be accepted by stakeholders. From this perspective, acceptance criteria may be viewed as the test
conditions that should be exercised by the tests. Acceptance criteria are usually a result of the Conversation.
Acceptance criteria are used to:
- Define the scope of the user story
- Reach consensus among the stakeholders
- Describe both positive and negative scenarios
- Serve as a basis for the user story acceptance testing (see section 4.5.3)
- Allow accurate planning and estimation
There are several ways to write acceptance criteria for a user story. The two most common formats are:
- Scenario-oriented (e.g., 
    - Given/When/Then format used in BDD, see section 2.1.3)
- Rule-oriented (e.g., bullet point verification list, or tabulated form of input-output mapping)

Most acceptance criteria can be documented in one of these two formats. However, the team may use
another, custom format, as long as the acceptance criteria are well-defined and unambiguous.

Keep them separate but group them logically if you want to show inheritance:
```User Story: Access Control
    AC1a: Regular users have access to floors 1 to 3
    AC1b: Special users inherit all Regular user permissions
    AC2: Special users additionally have access to floor 4
```
When you're writing acceptance criteria, **separation of concerns** means each AC should address one **distinct requirement** or behavior. 

# Acceptance Test-driven Development (ATDD)

ATDD is a test-first approach (see section 2.1.3). Test cases are created prior to implementing the user
story. The test cases are created by team members with different perspectives, e.g., customers,
developers, and testers (Adzic 2009). Test cases may be executed manually or automated.
The first step is a specification workshop where the user story and (if not yet defined) its acceptance
criteria are analyzed, discussed, and written by the team members. Incompleteness, ambiguities, or
defects in the user story are resolved during this process. The next step is to create the test cases. This
can be done by the team as a whole or by the tester individually. The test cases are based on the
acceptance criteria and can be seen as examples of how the software works. This will help the team
implement the user story correctly.
Since examples and tests are the same, these terms are often used interchangeably. During the test
design the test techniques described in sections 4.2, 4.3 and 4.4 may be applied.
Typically, the first test cases are positive, confirming the correct behavior without exceptions or error
conditions, and comprising the sequence of activities executed if everything goes as expected. After the
positive test cases are done, the team should perform negative testing. Finally, the team should cover
non-functional quality characteristics (e.g., performance efficiency, usability). Test cases should be
expressed in a way that is understandable for the stakeholders. Typically, test cases contain sentences in
natural language involving the necessary preconditions (if any), the inputs, and the postconditions.
The test cases must cover all the characteristics of the user story and should not go beyond the story.
However, the acceptance criteria may detail some of the issues described in the user story. In addition,
no two test cases should describe the same characteristics of the user story.
When captured in a format supported by a test automation framework, the developers can automate the
test cases by writing the supporting code as they implement the feature described by a user story. The
acceptance tests then become executable requirements.